{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pandas.read_csv('train.csv', index_col = 'PassengerId')\n",
    "train_index = data_train.index\n",
    "y_train = data_train['Survived']\n",
    "data_train.drop('Survived', inplace = True, axis = 1)\n",
    "#print(data_train[:5])\n",
    "data_test = pandas.read_csv('test.csv', index_col = 'PassengerId')\n",
    "test_index = data_test.index\n",
    "\n",
    "data = pandas.concat([data_train, data_test])\n",
    "#print(data_test[:5])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nan(X):\n",
    "    counts = X.count()\n",
    "    length = X.shape[0]\n",
    "    print('Full length:', length)\n",
    "    for i in counts[counts < length].index:\n",
    "        print(i, ': Non NaN num:', counts[i], ', Not NaN:', '%.3f' % (100*counts[i] / length), '%')\n",
    "    return\n",
    "\n",
    "def get_marital_status(name):\n",
    "    if (name.find('Mrs') != -1) or (name.find('Lady') != -1) or (name.find('Countess') != -1):\n",
    "        return 2\n",
    "    if (name.find('Miss') != -1) or (name.find('Mlle') != -1) or (name.find('Mme') != -1) or (name.find('Ms') != -1):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def get_cabin(x):\n",
    "    x = re.sub('[^A-Za-z ]', '', x)\n",
    "    return x[0]\n",
    "\n",
    "def prepare_data(X):\n",
    "    X = X.copy()\n",
    "    # print_nan(X)\n",
    "    X['NameLength'] = X['Name'].map(len)\n",
    "    \n",
    "    X['Title'] = X['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "    stat_min = 10\n",
    "    title_names = (X['Title'].value_counts() < stat_min)\n",
    "    X['Title'] = X['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "    X = pandas.get_dummies(X, columns = ['Title'], prefix='Title')\n",
    "    \n",
    "    X['MaritalStatus'] = X['Name'].map(get_marital_status)\n",
    "    X['is_Mr'] = X['MaritalStatus'].map(lambda x: 1 if x == 0 else 0)\n",
    "    X['is_Miss'] = X['MaritalStatus'].map(lambda x: 1 if x == 1 else 0)\n",
    "    X['is_Mrs'] = X['MaritalStatus'].map(lambda x: 1 if x == 2 else 0)\n",
    "    # X.drop('MaritalStatus', axis = 1, inplace = True)\n",
    "    \n",
    "    X['Age_known'] = X['Age'].isnull() == False\n",
    "    X['Age_known'] = X['Age_known'].map(lambda x: 1 if x else 0)\n",
    "    X['Age'] = X.groupby('Pclass')['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    X['Fare'] = X.groupby('Pclass')['Fare'].apply(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    X['Sex'] = X['Sex'].map(lambda x: 1 if x == 'male' else 0)\n",
    "    \n",
    "    X['Embarked'].fillna(value = 'S', inplace = True)\n",
    "    X = pandas.get_dummies(X, columns = ['Embarked'], prefix='Emb')\n",
    "    X['Cabin'] = X['Cabin'].map(lambda x: 'N' if pandas.isna(x) else x)\n",
    "    X['LB'] = X['Cabin'].map(lambda x: 1 if ((len(re.sub('[A-Za-z ]', '', x)) > 0) and (int(re.sub('[A-Za-z ]', '', x)) % 2 == 0)) else 0)\n",
    "    X['RB'] = X['Cabin'].map(lambda x: 1 if ((len(re.sub('[A-Za-z ]', '', x)) > 0) and (int(re.sub('[A-Za-z ]', '', x)) % 2 == 1)) else 0)\n",
    "    X['Cabin'] = X['Cabin'].map(get_cabin)\n",
    "    X = pandas.get_dummies(X, columns = ['Cabin'], prefix='Cabin')\n",
    "    # X['Cabin'] = X['Cabin'].map(lambda x: 0 if pandas.isna(x) else 1)\n",
    "    \n",
    "    X['FamilySize'] = X['SibSp'] + X['Parch']\n",
    "    #X['isAlone'] = X['FamilySize'].map(lambda x: 1 if x == 0 else 0)\n",
    "    \n",
    "    X['1class'] = X['Pclass'].map(lambda x: 1 if x == 1 else 0)\n",
    "    X['2class'] = X['Pclass'].map(lambda x: 1 if x == 2 else 0)\n",
    "    X['3class'] = X['Pclass'].map(lambda x: 1 if x == 3 else 0)\n",
    "    X.drop('Pclass', axis = 1, inplace = True)\n",
    "    X['FareBin'] = pandas.qcut(x = X['Fare'], q = 4, labels = False)\n",
    "    X['AgeBin'] = pandas.qcut(x = X['Age'], q = 4, labels = False)\n",
    "    \n",
    "    X['Age'] = X['Age'].map(np.log1p)\n",
    "    X['Fare'] = X['Fare'].map(np.log1p)\n",
    "    \n",
    "    X['Pass'] = 1\n",
    "    X = X.join(X.groupby('Ticket')['Pass'].sum().rename('PassInTicket'), on = 'Ticket')\n",
    "    X = X.join(X.groupby('Ticket')['Fare'].median().rename('TicketFare'), on ='Ticket')\n",
    "    X['TicketFare'] = X['TicketFare'].divide(X['PassInTicket'])\n",
    "    X['FamilyFare'] = X['Fare'].divide(X['FamilySize'] + 1)\n",
    "    X['FamilyName'] = X['Name'].map(lambda x: x.split(',')[0])\n",
    "    X = X.join(X.groupby('FamilyName')['Pass'].sum().rename('FamilySize_1'), on = 'FamilyName')\n",
    "    X['FamilyFare_1'] = X['Fare'].divide(X['FamilySize_1'] + 1)\n",
    "    X = pandas.get_dummies(X, columns = ['FamilyName'], prefix='FName')\n",
    "    X.drop('Pass', inplace = True, axis = 1)\n",
    "    \n",
    "    X['Ttype'] = X['Ticket'].str[0]\n",
    "    X = pandas.get_dummies(X, columns = ['Ttype'], prefix='Ttype')\n",
    "    \n",
    "    X = pandas.get_dummies(X, columns = ['FamilySize'], prefix='FamSize')\n",
    "    X = pandas.get_dummies(X, columns = ['Parch'], prefix='Parch')\n",
    "    X = pandas.get_dummies(X, columns = ['SibSp'], prefix='SibSp')\n",
    "    \n",
    "    X.drop(['Name', 'Ticket'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    return X\n",
    "\n",
    "X = prepare_data(data)\n",
    "X_train = X.copy()\n",
    "X_test = X.copy()\n",
    "X_train.drop(X_train[X_train.index > train_index[-1]].index, inplace = True)\n",
    "X_test.drop(X_test[X_test.index <= train_index[-1]].index, inplace = True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(X_train)\n",
    "x_test = scaler.transform(X_test)\n",
    "\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(X_train['Fare'].head())\n",
    "print(X_train['Fare'].tail())\n",
    "print(X_train.shape)\n",
    "print(X_test['Fare'].head())\n",
    "print(X_test['Fare'].tail())\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid = {'n_estimators' : [100, 200, 300], \n",
    "        'learning_rate' : [0.1, 0.2, 0.3], \n",
    "        'subsample' : [0.3, 0.5, 1], \n",
    "        'max_features' : [None, 'auto', 0.2, 0.3, 0.5, 1]}\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "gbc = GradientBoostingClassifier(random_state = 42)\n",
    "gs = GridSearchCV(gbc, grid, scoring = 'roc_auc', cv = cv)\n",
    "gs.fit(X = X_train, y = y_train)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "gbc = GradientBoostingClassifier(n_estimators = 200, learning_rate = 0.2, subsample = 0.5, max_features = None, random_state = 42)\n",
    "gbc_scores = np.mean(cross_val_score(estimator = gbc, X = x_train, y = y_train, cv=cv, scoring='roc_auc'))\n",
    "print (\"%.3f\" % gbc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = GradientBoostingClassifier(n_estimators = 200, learning_rate = 0.2, subsample = 0.5, max_features = None, random_state = 42)\n",
    "titanic.fit(x_train, y_train)\n",
    "y_test = pandas.DataFrame(data = {'Survived' : titanic.predict(x_test)})\n",
    "# y_test['Survived'] = pandas.DataFrame(titanic.predict(X_test))\n",
    "#y_test.index.name = 'PassengerId'\n",
    "y_test.index = X_test.index\n",
    "y_test.to_csv('titanic_predict.csv')\n",
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.Series(titanic.feature_importances_, index = X_train.columns).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 8)\n",
    "pca.fit(X_train)\n",
    "dispmax = 0.99\n",
    "disp = 0\n",
    "i = 0\n",
    "while (disp < dispmax):\n",
    "    disp += pca.explained_variance_ratio_[i]\n",
    "    i += 1    \n",
    "print('Для описания', dispmax, 'дисперсии требуется', i, 'компонент')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid = {'C' : [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000], \n",
    "        'penalty' : ['l1', 'l2']}\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "lr = LogisticRegression()\n",
    "gs = GridSearchCV(lr, grid, scoring = 'roc_auc', cv = cv)\n",
    "gs.fit(X = x_train, y = y_train)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = 0.01)\n",
    "lr_scores = np.mean(cross_val_score(estimator = lr, X = x_train, y = y_train, cv=cv, scoring='roc_auc'))\n",
    "print (\"%.3f\" % lr_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid = {'C' : [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000], \n",
    "        'class_weight' : [None, 'balanced']}\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "svm = SVC(random_state = 42)\n",
    "gs = GridSearchCV(svm, grid, scoring = 'roc_auc', cv = cv)\n",
    "gs.fit(X = x_train, y = y_train)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state = 42, C = 10, class_weight = 'balanced')\n",
    "svm_scores = np.mean(cross_val_score(estimator = svm, X = x_train, y = y_train, cv=cv, scoring='roc_auc'))\n",
    "print (\"%.3f\" % svm_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid = {'max_depth' : [None, 1, 5, 10, 50, 100, 500],\n",
    "        'min_samples_split' : [2, 0.01, 0.05, 0.1, 0.5, 0.9],\n",
    "        'min_samples_leaf' : [1, 2, 3, 0.01, 0.05, 0.1, 0.5], \n",
    "        'max_features' : [None, 'auto', 'sqrt', 'log2'], \n",
    "        'class_weight' : [None, 'balanced']}\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "dt = DecisionTreeClassifier(random_state = 42)\n",
    "gs = GridSearchCV(dt, grid, scoring = 'roc_auc', cv = cv)\n",
    "gs.fit(X = x_train, y = y_train)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(class_weight='balanced', max_depth=5, max_features=None, min_samples_leaf=0.01, min_samples_split=0.05)\n",
    "dt_scores = np.mean(cross_val_score(estimator = dt, X = x_train, y = y_train, cv=cv, scoring='roc_auc'))\n",
    "print (\"%.3f\" % dt_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid = {'n_estimators' : [50, 100, 200, 300], \n",
    "        'learning_rate' : [0.1, 0.2, 0.3], \n",
    "        'algorithm': ['SAMME', 'SAMME.R']}\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "ada = AdaBoostClassifier(random_state = 42)\n",
    "gs = GridSearchCV(ada, grid, scoring = 'roc_auc', cv = cv)\n",
    "gs.fit(X = x_train, y = y_train)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(random_state = 42, n_estimators = 100, learning_rate = 0.3)\n",
    "ada_scores = np.mean(cross_val_score(estimator = ada, X = x_train, y = y_train, cv=cv, scoring='roc_auc'))\n",
    "print (\"%.3f\" % ada_scores)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid = {'n_estimators' : [50, 100, 200, 300],\n",
    "        'max_features' : ['auto', 'sqrt', 'log2', None], \n",
    "        'class_weight' : [None, 'balanced', 'balanced_subsample']}\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "gs = GridSearchCV(rf, grid, scoring = 'roc_auc', cv = cv)\n",
    "gs.fit(X = x_train, y = y_train)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 42, n_estimators = 50, class_weight = 'balanced_subsample')\n",
    "rf_scores = np.mean(cross_val_score(estimator = rf, X = X_train, y = y_train, cv=cv, scoring='roc_auc'))\n",
    "print (\"%.3f\" % rf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "GB = GradientBoostingClassifier(n_estimators = 200, learning_rate = 0.2, subsample = 0.5, max_features = None, random_state = 42)\n",
    "LR = LogisticRegression(C = 0.01)\n",
    "SV = SVC(random_state = 42, C = 10, class_weight = 'balanced', probability = True)\n",
    "ADA = AdaBoostClassifier(random_state = 42, n_estimators = 100, learning_rate = 0.3)\n",
    "DT = DecisionTreeClassifier(class_weight='balanced', max_depth=5, max_features=None, min_samples_leaf=0.01, min_samples_split=0.05)\n",
    "RF = RandomForestClassifier(random_state = 42, n_estimators = 50, class_weight = 'balanced_subsample')\n",
    "\n",
    "VC = VotingClassifier(estimators=[('gbc', GB), ('lr', LR), ('svc', SV), ('ada', ADA), ('dt', DT), ('rf', RF)], voting='soft', n_jobs=-1)\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "vc_scores = np.mean(cross_val_score(estimator = VC, X = x_train, y = y_train, cv=cv, scoring='roc_auc'))\n",
    "print (\"%.3f\" % vc_scores)\n",
    "\n",
    "VC = VC.fit(x_train, y_train)\n",
    "y_test = pandas.DataFrame(data = {'Survived' : VC.predict(x_test)})\n",
    "y_test.index = X_test.index\n",
    "y_test.to_csv('titanic_predict_voting.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n",
    "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=group_names)\n",
    "    df.Age = categories\n",
    "    return df\n",
    "\n",
    "df['Sex'] = df['Sex'].map({'female': 1, 'male': 0}).astype(int)\n",
    "df['Sex'] = df['Sex'].replace(['male', 'female'], [0, 1])\n",
    "df['Sex'].replace(['male','female'],[0,1],inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "def cabin_encode(X_train, X_test):\n",
    "    le = LabelEncoder()\n",
    "    ohe = OneHotEncoder(sparse = False)\n",
    "    ohe.fit(le.fit_transform(pandas.concat([X_train, X_test])).reshape(-1, 1))\n",
    "    col_train = pandas.DataFrame(ohe.transform(le.transform(X_train).reshape(-1, 1)))\n",
    "    col_train.columns = ['Cabin_' + str(int(i)) for i in range(col_train.shape[1])]\n",
    "    col_test = pandas.DataFrame(ohe.transform(le.transform(X_test).reshape(-1, 1)))\n",
    "    col_test.columns = col_train.columns\n",
    "    col_train.index = X_train.index\n",
    "    col_test.index = X_test.index\n",
    "    return col_train, col_test\n",
    "cabin_train, cabin_test = cabin_encode(X_train['Cabin'], X_test['Cabin'])\n",
    "X_train = X_train.join(cabin_train)\n",
    "X_test = X_test.join(cabin_test)\n",
    "X_train.drop('Cabin', axis = 1, inplace = True)\n",
    "X_test.drop('Cabin', axis = 1, inplace = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
